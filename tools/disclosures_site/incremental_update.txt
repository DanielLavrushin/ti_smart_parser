# Процесс создание базы disclosures = dlrobot+declarator

#======================================================================
#========                     Инициализация                    ========
#=====================================================================

#1.1 идем в  ~/smart_parser/tools/INSTALL.txt и выполняем все шаги

#1.2. Объявление переменных (кроме тех, что уже объявлены в ~/smart_parser/tools/INSTALL.txt)

export TOOLS=~/smart_parser/tools
export DLROBOT_UPDATES_FOLDER=~/declarator_hdd/declarator/dlrobot_updates
export HUMAN_FILES_JSON=~/declarator_hdd/declarator/human_files.json
export HUMAN_FILES_FOLDER=~/declarator_hdd/declarator/human_files
export HUMAN_JSONS_FOLDER=~/declarator_hdd/declarator/human_jsons

export INPUT_DLROBOT_PROJECTS=input_projects
export DISCLOSURES_FILES=domains
export PYTHONPATH=$TOOLS/disclosures_site:$TOOLS



#======================================================================
#======== Обновление ручной базы (declarator), раз в квартал?  ========
#=====================================================================
#2.1 построение базы declarator:
    cd ~
    git clone sokirko@bitbucket.org:TI-Russia/declarator.git
    cd declarator/trasparency
    pip3 install -r ../deploy/requirements.txt
    echo "CREATE DATABASE declarator CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci
    create user if not exists 'declarator'@ identified by 'declarator';
    GRANT ALL PRIVILEGES ON *.* TO 'declarator'@;" | mysql
    #browse https://declarator.org/manage/dump_files/ и найти свежий дамп
    wget https://declarator.org/manage/dump_files/prod????.tar.gz
    zcat prod????.tar.gz | mysql -D declarator


#2.2  получить все новые (!) файлы из declarator в каталог $HUMAN_FILES_FOLDER и создать файл human_files.json
    python $TOOLS/disclosures_site/scripts/export_human_files.py --table declarations_documentfile --output-folder $HUMAN_FILES_FOLDER --output-json $HUMAN_FILES_JSON

#2.3  Отправляем все новые Pdf на конвертацию
    find $HUMAN_FILES_FOLDER -name '*.pdf' |  xargs --verbose -n 10  python $TOOLS/ConvStorage/scripts/convert_pdf.py --skip-receiving

#2.4 создание ручных json
    [ -d  $HUMAN_JSONS_FOLDER ] || mkdir $HUMAN_JSONS_FOLDER
    cd ~/declarator/transparency
    source ../venv/bin/activate
    python3 manage.py export_in_smart_parser_format --output-folder $HUMAN_JSONS_FOLDER


#======================================================================
#======== Получение данных от dlrobot (раз в месяц?)            ========
#=====================================================================

#3.1 создание нового каталога
    cd $DLROBOT_UPDATES_FOLDER/
    export OLD_DLROBOT_FOLDER=`find -mindepth 1 -maxdepth 1 -xtype d  | sort | tail -n 1 | xargs -n 1 realpath`
    # all projects that older than 5 hours in order not to get a race condition
    export CRAWL_EPOCH=`python3 -c "import time; print (int(time.time() - 60 * 5))"`
    export DLROBOT_FOLDER=$DLROBOT_UPDATES_FOLDER/$CRAWL_EPOCH

    mkdir -p $DLROBOT_FOLDER
    cd $DLROBOT_FOLDER


#3.2  слияние по файлам dlrobot, declarator  и старого disclosures, получение dlrobot_human.json
    python3 $TOOLS/disclosures_site/scripts/join_human_and_dlrobot.py \
        --max-ctime $CRAWL_EPOCH \
        --input-dlrobot-folder  $DLROBOT_CENTRAL_FOLDER"/processed_projects" \
        --human-json $HUMAN_FILES_JSON \
        --old-dlrobot-human-json $OLD_DLROBOT_FOLDER/dlrobot_human.json \
        --output-domains-folder $DISCLOSURES_FILES \
        --output-json dlrobot_human.json


#3.3  получение статистики по dlrobot_human.json, сравнение с предыдущим обходом
    python3 $TOOLS/disclosures_site/scripts/dlrobot_human_stats.py dlrobot_human.json > dlrobot_human.json.stats

#3.4 новый смартпарсер через старые файлы dlrobot
  python3 $TOOLS/robots/dlrobot/scripts/cloud/smart_parser_cache_client.py  --walk-folder-recursive $DISCLOSURES_FILES --action put

#3.5  (факультативно) переконвертация  pdf, которые не были переконвертированы раньше
 find  $DISCLOSURES_FILES -name '*.pdf' -type f | xargs -n 100 --verbose python $TOOLS/ConvStorage/scripts/convert_pdf.py --skip-receiving --conversion-timeout 20

#3.6  (факультативно) Запуск текущего классификатора на старых файлах из dlrobot и удаление тех, что не прошел классификатор
  find  $DISCLOSURES_FILES -name 'o*' -type f | xargs -P 4 -n 1 --verbose python $TOOLS/DeclDocRecognizer/dlrecognizer.py --delete-negative --source-file
  python $TOOLS/disclosures_site/scripts/clear_json_entries_for_deleted_files.py dlrobot_human.json
  python $TOOLS/disclosures_site/scripts/dlrobot_human_stats.py dlrobot_human.json > dlrobot_human.json.stats


#3.7  Создание базы первичных ключей старой базы, чтобы поддерживать постоянство веб-ссылок
   python3 $TOOLS/disclosures_site/manage.py create_permalink_storage  --settings disclosures.settings.prod --output-dbm-file permalinks.dbm
   # возможно python3 /var/... disclosures_site/manage.py, поскольку в $TOOLS/disclosures_site/ - новый код


#3.8.  инициализация базы disclosures
    cd ~/smart_parser/tools/disclosures_site
    sudo python3 manage.py create_database --settings disclosures.settings.dev --password ??? --skip-checks
    python3 manage.py makemigrations --settings disclosures.settings.dev
    python3 manage.py migrate --settings disclosures.settings.dev
    python3 manage.py test declarations/tests --settings disclosures.settings.dev


#3.8.1
    cd $DLROBOT_FOLDER
    python3 $TOOLS/disclosures_site/manage.py create_sql_sequences  --settings disclosures.settings.dev --permanent-links-db permalinks.dbm


#3.9.  Импорт json в dislosures_db
   python3 $TOOLS/disclosures_site/manage.py clear_database --settings disclosures.settings.dev
   python3 $TOOLS/disclosures_site/manage.py import_json \
               --settings disclosures.settings.dev \
               --smart-parser-human-json-folder $HUMAN_JSONS_FOLDER \
               --dlrobot-human dlrobot_human.json   \
               --process-count 3  \
               --permanent-links-db permalinks.dbm

   python3 $TOOLS/disclosures_site/manage.py copy_person_id
        --settings disclosures.settings.dev \
        --permanent-links-db permalinks.dbm

#9.  (факультативно) тестирование сливалки
   export DEDUPE_MODEL=~/declarator/transparency/toloka/dedupe_model/dedupe.info

   cd $TOOLS/disclosures_site/toloka/pools
   bash -x make_pools.sh

#10.  запуск сливалки, 4 gb memory each family portion, 30 GB temp files, no more than one process per workstation
   python3 $TOOLS/disclosures_site/manage.py generate_dedupe_pairs  --print-family-prefixes   --permanent-links-db $DLROBOT_FOLDER/permalinks.dbm --settings disclosures.settings.dev > surname_spans.txt
   python3 $TOOLS/disclosures_site/manage.py clear_dedupe_artefacts --settings disclosures.settings.dev
   export DISCLOSURES_DB_HOST=migalka
   export DEDUPE_HOSTS=lena,avito
   export DEDUPE_HOSTS_SPACES="lena avito"
   for host in $DEDUPE_HOSTS_SPACES; do
        scp $DLROBOT_FOLDER/permalinks.dbm $host:/tmp
        ssh $host git -C ~/smart_parser pull
        ssh $host touch /tmp/dlrobot_worker/.dlrobot_pit_stop
   done
   sleep 3h # till dlrobot worker stops
   parallel -a surname_spans.txt --jobs 2 --env DISCLOSURES_DB_HOST --env PYTHONPATH -S $DEDUPE_HOSTS --basefile $DEDUPE_MODEL  --verbose --workdir /tmp \
        python3 $TOOLS/disclosures_site/manage.py generate_dedupe_pairs --permanent-links-db /tmp/permalinks.dbm --dedupe-model-file $DEDUPE_MODEL  \
                --verbose 3  --threshold 0.9  --surname-bounds {} --write-to-db --settings disclosures.settings.dev --logfile dedupe.{}.log
                 

#11  Коммит статистики
   cd $TOOLS/disclosures_site
   python3 manage.py add_disclosures_statistics --settings disclosures.settings.dev --crawl-epoch $CRAWL_EPOCH
   git commit -m "new statistics" data/statistics.json
   git push

#12
 cd $DLROBOT_FOLDER
 mysqldump -u disclosures -pdisclosures disclosures_db_dev  |  gzip -c > $DLROBOT_FOLDER/disclosures.sql.gz

#13. создание индексов для elasticsearch
   python3 manage.py search_index --rebuild  --settings disclosures.settings.dev

#14 go to prod (migalka), disclosures.ru is offline
    cd /var/www/smart_parser/tools/disclosures_site

    # it takes more than 30 minutes  to unpack database, in future we have to use a temp databse
    # something like this (not tested yet)
    export DISCLOSURES_DATABASE_NAME=disclosures_prod_temp
    sudo python3 manage.py create_database --settings disclosures.settings.prod --password ??? --skip-checks
    zcat $DLROBOT_FOLDER/disclosures.sql.gz | mysql -u disclosures -pdisclosures -D $DISCLOSURES_DATABASE_NAME
    python3 manage.py elastic_manage --action backup-prod --settings disclosures.settings.dev
    python3 manage.py elastic_manage --action dev-to-prod --settings disclosures.settings.dev
    sudo systemctl stop disclosures
    sudo systemctl start disclosures
    # now prod works on database disclosures_prod_temp


    export DISCLOSURES_DATABASE_NAME=disclosures_db
    mysqladmin drop  $DISCLOSURES_DATABASE_NAME -u disclosures -pdisclosures
    sudo python3 manage.py create_database --settings disclosures.settings.prod --password ??? --skip-checks
    zcat $DLROBOT_FOLDER/disclosures.sql.gz | mysql -u disclosures -pdisclosures -D $DISCLOSURES_DATABASE_NAME
    sudo systemctl stop disclosures
    sudo systemctl start disclosures
    # now prod works on database disclosures_db

    mysqladmin drop  disclosures_prod_temp -u disclosures -pdisclosures


    # to rebuild one index
    #python3 manage.py search_index --rebuild  -f --settings disclosures.settings.dev --models declarations.Section

    # index sizes
    # curl 127.0.0.1:9200/_cat/indices

    # some query example
    #curl -X GET "localhost:9200/declaration_file_prod/_search?pretty" -H 'Content-Type: application/json' -d'{"query": {"match" : {"office_id" : 5963}}}'
     rm -rf disclosures/static/domains
     ln -s  $DLROBOT_FOLDER/$DISCLOSURES_FILES disclosures/static/domains
     sudo systemctl stop disclosures
     sudo systemctl start disclosures

#15  посылаем данные dlrobot в облако
    python3 $TOOLS/disclosures_site/scripts/send_source_documents_to_cloud.py  --max-ctime $CRAWL_EPOCH \
        --input-dlrobot-folder $DLROBOT_CENTRAL_FOLDER"/processed_projects" --output-cloud-folder declarator/dlrobot_updates \

